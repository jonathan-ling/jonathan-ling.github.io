{
  "projects": [
    {
      "title": "Cryptocurrency Alpha Models via Intraday Technical Trading",
      "client": "Stanford University course project (<a href=\"https://explorecourses.stanford.edu/search?q=MS%26E448&academicYear=20202021\" target=\"_blank\">MS&E 448</a> - Big Financial Data and Algorithmic Trading)",
      "tags": [
        "Data Science",
        "Machine Learning"
      ],
      "image": "images/lagged-linear-regression-backtrader.png",
      "description": "Cryptocurrency tends to be significantly more volatile than stocks, but returns can be significantly greater using high-frequency trading strategies. Further, non-technical signals such as sentiment analysis on social media, have traditionally been used as key indicators of cryptocurrency trends. In contrast, this paper seeks to explore sources of alpha or excess returns, that can be found from technical analysis alone, using a pairs trading strategy, lagged linear regression and three other machine learning models – NeuralProphet, XGBoost and recurrent neural networks. Generally, we found that the high volatility of cryptocurrency assets at the hourly level was challenging to model but still able to be profitably monetized. Our lagged linear regression model performed best with a Sharpe ratio of 3.34.",
      "artefacts": [
        {
          "Paper": "artefacts/2021.06 Intraday technical trading for cryptocurrencies - paper.pdf",
          "Presentation": "artefacts/2021.06 Intraday technical trading for cryptocurrencies - presentation.pdf",
          "GitHub": "https://github.com/jonathan-ling/msande-448-final-project"
        }
      ]
    },
    {
      "title": "Six Approaches to Improve BERT for Claim Verification as Applied to the Fact Extraction and Verification Challenge (FEVER) Dataset",
      "client": "Stanford University course project (<a href=\"https://explorecourses.stanford.edu/search?q=CS224N&academicYear=20202021\" target=\"_blank\">CS 224N</a> - Natural Language Processing with Deep Learning)",
      "tags": [
        "Data Science",
        "Machine Learning"
      ],
      "image": "images/natural-language-processing.png",
      "description": "BERT, a transformer-based model often used in natural language processing, has been used in various research for fact extraction and verification tasks, but suffers from various issues when applied to claim verification. In this project, we aimed to implement the BERT model for claim verification on the FEVER (Fact Extraction and Verification) dataset, and suggest and implement six improvement approaches to the original BERT model - pre-processing evidence via data augmentation (synonym replacement and back-translation), changing the transformer settings (BERT vs DistilBERT and number of epochs), and post- processing its results neurally. While our modifications did not result in significant changes to the FEVER score, likely due to BERT's strong pre-training, applying our neural aggregation layer improved performance on the DistilBERT model, a lighter version of the BERT model.",
      "artefacts": [
        {
          "Paper": "artefacts/2021.03 BERT FEVER.pdf",
          "GitHub": "https://github.com/jonathan-ling/cs-224n-final-project"
        }
      ]
    },
    {
      "title": "Augmenting Node Information for Homogeneous Graphs",
      "client": "Stanford University course project (<a href=\"https://explorecourses.stanford.edu/search?q=CS224W&academicYear=20202021\" target=\"_blank\">CS 224W</a> - Machine Learning with Graphs)",
      "tags": [
        "Data Science",
        "Machine Learning"
      ],
      "image": "images/graph-neural-networks.png",
      "description": "Graph Neural Network (GNN) aggregation schemes involve recursively aggregating representations of network nodes, but popular methods such as mean-pooling in Graph Convolutional Networks (GCNs) and max-pooling in GraphSAGE are not able to adequately distinguish some basic graph structures, including symmetrical ones. In our paper, we use the link prediction task on the drug-drug interaction dataset from Open Graph Benchmark to analyze the impacts of adding different types of information. We investigate the usage of different random initializations of embeddings, which are updated across epochs, static node information that is constant across epochs, and pre-trained model embeddings. Compared to using a uniform distribution for the embeddings, we determine that a combination of binarized k-hop, cycle, and subgraph features with static Xavier initialization performs significantly better than the baseline.",
      "artefacts": [
        {
          "Paper": "artefacts/2021.03 GNNs - augmenting node information.pdf",
          "GitHub": "https://github.com/jonathan-ling/cs-224w-final-project"
        }
      ]
    },
    {
      "title": "Prioritizing Order Scheduling Under Resource Constraints in a CPG Supply Chain",
      "client": "Niagara Bottling internship",
      "tags": [
        "Operations Research",
        "Mathematical Optimization"
      ],
      "image": "images/cpg-warehouse.png",
      "description": "In supply chain distribution, customer orders are fulfillable only if all the product and logistical resources required to do so are available; otherwise, it must be rescheduled. Three key resources required are the product, carrier (i.e., truck) and dock (i.e., warehouse loading space). To avoid wasting scheduling efforts, schedulers must decide whether to schedule or reschedule each order with respect to the customers’ desired delivery date before taking that action, while considering penalties to reschedule. In this project, I formulated a binary integer program as a variant of the knapsack problem in operations research, to optimize the prioritization sequence of orders under resource contention constraints.",
      "artefacts": [
        {
          "Paper": "artefacts/2020.08 Scheduling.pdf"
        }
      ]
    },
    {
      "title": "Developing a Digital Scheduling Product for the US Air Force",
      "client": "Stanford University course project (<a href=\"https://explorecourses.stanford.edu/search?q=MS%26E297&academicYear=20192020\" target=\"_blank\">MS&E 297</a> - \"Hacking for Defense\": Solving National Security issues with the Lean Launchpad) taught by Steve Blank, pioneer of the Lean Launchpad methodology",
      "tags": [
        "Entrepreneurship",
        "Lean Launchpad",
        "Customer Discovery",
        "Operations Research"
      ],
      "image": "images/time-flies-mvp.png",
      "description": "Within the US Air Force, mobility squadron schedulers resort to manual schedule generation methods, including using whiteboards and Excel spreadsheets. This often leads to brittle schedules, with which enacting last-minute changes results in significant ramifications on squadron morale while impacting personal and training time. During this course, our team conducted 130+ customer discovery interivews and iterated through several MVPs (minimum viable products) to develop a digital scheduling product that would improve the disparate interfaces schedulers use while optimizing schedule generation algorithmically, to lead to improved scheduling efficiency, crew rest and safety, and deployment responsiveness.",
      "artefacts": [
        {
          "Video": "https://www.youtube.com/watch?v=WrYpxD58Wh0",
          "Presentation": "https://www.slideshare.net/sblank/time-flies-h4d-2020-lessons-learned"
        }
      ]
    },
    {
      "title": "Dynamically Pricing Airline Tickets Using Reinforcement Learning",
      "client": "Stanford University course project (<a href=\"https://explorecourses.stanford.edu/search?q=AA228&academicYear=20192020\" target=\"_blank\">AA 228</a> - Decision Making Under Uncertainty)",
      "tags": [
        "Data Science",
        "Machine Learning"
      ],
      "image": "images/doubleAgentSarsa-2policy.png",
      "description": "In the airline industry, dynamic pricing is a common tool for revenue management, where an airline's goal is to set ticket prices to maximize its revenue over a finite time horizon. This paper considers the case of pricing a specific inventory item (e.g., economy class tickets) that is sold to different customer segments based on their inputs when purchasing the ticket (e.g., days to departure, one way/return, length of trip, etc.) and which thus has different price points. We review common approaches taken to solve the single-segment (i.e., single price point) dynamic pricing problem and formulate a multi-segment (i.e., multiple price points) dynamic pricing problem using a factored multi-agent Markov decision process (MMDP) framework. We solve the multi-segment dynamic pricing problem using modern reinforcement learning (RL) approaches including Sarsa and Sarsa-Lambda, and compare the performance of these approaches to various baseline policies.",
      "artefacts": [
        {
          "Paper": "https://github.com/jonathan-ling/aa-228/raw/master/final-project/doc/final_revisedjan2020.pdf",
          "GitHub": "https://github.com/jonathan-ling/aa-228"
        }
      ]
    },
    {
      "title": "Optimizing Passenger Flow at an Airport",
      "client": "Accenture project with an airport client",
      "tags": [
        "Operations Analytics",
        "Data Visualization"
      ],
      "image": "images/airport-client.jpeg",
      "description": "This project involved building an enterprise data platform from scratch for a major Australian airport to monitor and improve passenger flow and reduce congestion. I was involved in designing the database structure for integration in Azure, modeling WiFi data to track and predict foot traffic, and building visualizations in Power BI. The platform provided the client's central operations tower with a real-time dashboard feed of passenger flow and areas of congestion at the arrival and departure terminals, enabling proactive flow management. It ultimately won an industry Technology award from the Australian Airports Association for innovation and excellence.",
      "artefacts": []
    },
    {
      "title": "Predicting Repeat Callers with Classifier Models",
      "client": "Accenture project with an energy utility client",
      "tags": [
        "Data Science",
        "Machine Learning"
      ],
      "image": "images/energy-client.png",
      "description": "This project aimed to help an energy utility client streamline its customer contact points and reduce call center costs. I designed a database for the purpose of customer multi-channel analysis (channels being the website, phone, app, etc.) as an analytic record — an architectural pattern that has the advantage of being easily added to by a real-time stream of records, and which is readily consumable by a machine learning model. I also built a predictive model to classify repeat callers using random forest and XGBoost classifier models in Python, and used average precision as the performance metric due to imbalanced classes. The random forest model achieved an average precision score of 0.7, translating into potential savings in proactive call management of several million dollars per year.",
      "artefacts": []
    },
    {
      "title": "Predicting Modem Flaps with Decision Tree Classification",
      "client": "Accenture project with a telco client",
      "tags": [
        "Data Science",
        "Machine Learning",
        "Data Visualization"
      ],
      "image": "images/telco-client-flaps.png",
      "description": "This project aimed to help a telco client improve its ability to manage modem flaps (intermittent connectivity dropouts from the network). Flapping issues could be classified as originating from the customer or the network, which should be treated differently but had been indistinguishable to the client. I built a classifier model by using a decision tree-based model and graph database (Neo4j) to identify close-proximity groups of problematic nodes. To aid modeling and stakeholder communication, I also visualized the telco network graph, both geographically (with R's leaflet package) and logically (with R's visNetwork package).",
      "artefacts": []
    },
    {
      "title": "Improving Workforce Management Processes with the Theory of Constraints",
      "client": "Accenture project with a telco client",
      "tags": [
        "Operations Analytics",
        "Theory of Constraints"
      ],
      "image": "images/telco-client-workforce.png",
      "description": "This project aimed to help a telco client improve the forecasting accuracy and capacity management processes of their technician workforce. After analyzing the processes involved, I challenged the idea that improving forecasting accuracy was the real goal. Using the Theory of Constraints, a management paradigm built on operations research principles, I identified the overarching goal (connecting end users efficiently to the network) and key conflict (lead time required) to propose a solution that would not only improve the project's initial KPIs but also significantly reduce operational expenses.",
      "artefacts": []
    },
    {
      "title": "Optimizing Fiber-optic Network Design with Mixed Integer Programming and Gurobi",
      "client": "Biarri project with an Internet provider client",
      "tags": [
        "Operations Research",
        "Mathematical Optimization"
      ],
      "image": "images/network-design.jpg",
      "description": "This project aimed to help a national Internet provider to design cost-efficient layouts of a fiber-optic Internet network to cities of around 20,000 homes each. This was mathematically formulated as a mixed integer program and solved using Gurobi, an optimization software. The company’s software reduced design time by 80% as compared to traditional layout planning methods.",
      "artefacts": []
    },
    {
      "title": "Creating This Portfolio Website",
      "client": "Personal project",
      "tags": [
        "Web Development"
      ],
      "image": "images/website.png",
      "description": "I created this portfolio website from scratch, using HTML, CSS, JavaScript, AngularJS, JQuery and Bootstrap. It is a single page application (SPA) so that moving to a different page doesn't cause the browser to refresh. The code is also structured modularly with the model-view-controller pattern — that is, the code for the content, skin and display mechanism respectively are separated.",
      "artefacts": [
        {
          "GitHub": "https://github.com/jonathan-ling/jonathan-ling.github.io"
        }
      ]
    }
  ]
}